# AI-Powered Security Vulnerability Analysis Pipeline

## Overview

This comprehensive DevSecOps security analysis pipeline integrates multiple security scanning tools with AI-powered analysis using **DeepSeek R1** and **Llama** models from HuggingFace to generate executive summaries, remediation policies, technical playbooks, and compliance traceability mappings.

## üéØ Features

### Security Scanning Tools
- **Gitleaks** - Secrets scanning and detection
- **Semgrep** - Static Application Security Testing (SAST)
- **OWASP Dependency-Check** - Software Composition Analysis (SCA)
- **Trivy** - Container image vulnerability scanning
- **OWASP ZAP** - Dynamic Application Security Testing (DAST)

### AI-Powered Analysis
- **Executive Summaries** - C-level friendly security posture reports
- **Remediation Policies** - Prioritized remediation strategies with timelines
- **Technical Playbooks** - Detailed implementation guides with code examples
- **Risk Assessments** - Business impact and likelihood analysis
- **Compliance Mapping** - ISO 27001, PCI-DSS, OWASP Top 10, CWE alignment

### Report Generation
- **Comprehensive HTML Reports** - Full technical analysis for security teams
- **Executive HTML Reports** - Simplified summaries for leadership
- **Technical Playbook Reports** - Action-oriented guides for DevOps teams
- **Print-friendly formats** - Professional, paginated PDF-ready outputs

## üìÅ Project Structure

```
intelligent-stock-market-monitoring-platform-backend/
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ process_vulnerabilities.py      # Vulnerability normalization script
‚îÇ   ‚îú‚îÄ‚îÄ gitleaks-report.json            # Generated by Gitleaks
‚îÇ   ‚îú‚îÄ‚îÄ semgrep-report.json             # Generated by Semgrep
‚îÇ   ‚îú‚îÄ‚îÄ dependency-check-report.json    # Generated by OWASP Dependency-Check
‚îÇ   ‚îú‚îÄ‚îÄ trivy-report.json               # Generated by Trivy
‚îÇ   ‚îú‚îÄ‚îÄ zap-report.json                 # Generated by OWASP ZAP
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_security_report.html
‚îÇ   ‚îú‚îÄ‚îÄ executive_summary_report.html
‚îÇ   ‚îî‚îÄ‚îÄ technical_playbook_report.html
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ normalized_vulnerabilities.json  # Unified vulnerability data
‚îú‚îÄ‚îÄ ai-policies/
‚îÇ   ‚îî‚îÄ‚îÄ llm_generated_policy.json       # AI-generated policies and insights
‚îú‚îÄ‚îÄ llm_integration.py                  # LLM integration module
‚îú‚îÄ‚îÄ html_report_generator.py            # HTML report generation
‚îú‚îÄ‚îÄ real_llm_integration.py             # Main orchestration script
‚îú‚îÄ‚îÄ requirements-security.txt           # Python dependencies
‚îî‚îÄ‚îÄ jenkinsfile                         # Jenkins pipeline configuration
```

## üöÄ Getting Started

### Prerequisites

1. **HuggingFace API Token**
   - Sign up at [HuggingFace](https://huggingface.co/)
   - Create an API token from Settings > Access Tokens
   - Set environment variable: `export HF_TOKEN='your_token_here'`

2. **Python 3.8+**
   ```bash
   python3 --version
   ```

3. **Docker** (for security tools)
   ```bash
   docker --version
   ```

### Installation

1. **Install Python dependencies:**
   ```bash
   pip install -r requirements-security.txt
   ```

2. **Set HuggingFace API token:**
   ```bash
   export HF_TOKEN='your_huggingface_token'
   ```

3. **Configure Jenkins credentials:**
   - Add HuggingFace token as Jenkins Secret Text credential
   - ID: `huggingface-token`

## üìä Usage

### Running the Complete Pipeline

The Jenkins pipeline automatically executes all stages. To run manually:

#### Step 1: Run Security Scans

```bash
# Create report directories
mkdir -p reports processed ai-policies

# Run Gitleaks
docker run --rm -v $(pwd):/workspace \
    zricethezav/gitleaks:latest \
    detect --source /workspace \
    --report-path /workspace/reports/gitleaks-report.json \
    --report-format json --no-git

# Run Semgrep
docker run --rm -v $(pwd):/src \
    returntocorp/semgrep \
    scan --config=p/python \
    --json --output=/src/reports/semgrep-report.json /src

# Run Dependency-Check
docker run --rm -v $(pwd):/src \
    owasp/dependency-check:latest \
    --scan /src --format JSON --format HTML \
    --out /src/reports --project "Stock Market Platform"

# Run Trivy
docker run --rm \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v $(pwd)/reports:/reports \
    aquasec/trivy:latest \
    image --format json \
    --output /reports/trivy-report.json \
    your-image:tag
```

#### Step 2: Normalize Vulnerability Reports

```bash
cd reports
python3 process_vulnerabilities.py
```

This creates: `processed/normalized_vulnerabilities.json`

#### Step 3: Generate AI Insights and HTML Reports

```bash
python3 real_llm_integration.py
```

This generates:
- `ai-policies/llm_generated_policy.json` - AI-generated policies
- `reports/comprehensive_security_report.html` - Full report
- `reports/executive_summary_report.html` - Executive summary
- `reports/technical_playbook_report.html` - Technical guide

### Running Individual Components

#### Normalize Reports Only
```bash
python3 reports/process_vulnerabilities.py
```

#### Generate AI Insights Only
```bash
python3 -c "
from llm_integration import SecurityAnalysisLLM
import json
import os

llm = SecurityAnalysisLLM(os.environ['HF_TOKEN'])
with open('processed/normalized_vulnerabilities.json', 'r') as f:
    data = json.load(f)

summary = llm.generate_executive_summary(data)
print(summary)
"
```

#### Generate HTML Reports Only
```bash
python3 -c "
from html_report_generator import HTMLReportGenerator
import json

generator = HTMLReportGenerator()
with open('processed/normalized_vulnerabilities.json', 'r') as f:
    vuln_data = json.load(f)
with open('ai-policies/llm_generated_policy.json', 'r') as f:
    ai_data = json.load(f)

html = generator.generate_full_report(vuln_data, ai_data['insights'])
generator.save_report(html, 'reports/custom_report.html')
"
```

## ü§ñ AI Models Used

### DeepSeek R1 (Primary)
- **Model:** `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`
- **Purpose:** Advanced reasoning for security analysis
- **Use Cases:** Executive summaries, risk assessment, policy generation

### Llama 3.2 (Fallback)
- **Model:** `meta-llama/Llama-3.2-3B-Instruct`
- **Purpose:** Instruction-following for technical playbooks
- **Use Cases:** Technical guidance, remediation steps

### Switching Models
```python
from llm_integration import SecurityAnalysisLLM

# Use DeepSeek (default)
llm = SecurityAnalysisLLM(hf_token, preferred_model="deepseek")

# Use Llama
llm = SecurityAnalysisLLM(hf_token, preferred_model="llama")

# Generate with specific model
response = llm.generate(prompt, model="llama")
```

## üìã Generated Reports

### 1. Comprehensive Security Report
**Audience:** Security teams, DevOps engineers, Compliance officers

**Sections:**
- Executive Summary (AI-generated)
- Overall Security Posture
- Security Tools Utilized
- Detailed Vulnerability List
- AI-Generated Remediation Policy
- Technical Remediation Playbook
- Risk Assessment
- Compliance & Standards Mapping
- Key Recommendations

### 2. Executive Summary Report
**Audience:** C-level executives, Management, Board members

**Sections:**
- Security Posture at a Glance
- Executive Summary (AI-generated, non-technical)
- Business Risk Assessment
- Immediate Action Items

### 3. Technical Playbook Report
**Audience:** DevOps engineers, Security engineers, Developers

**Sections:**
- Remediation Strategy
- Technical Implementation Guide (with code snippets)
- Detailed Vulnerability List (top 50)
- Compliance Mapping

## üé® Report Features

### Professional Styling
- **Print-ready** - Optimized for A4 paper
- **Color-coded severity** - Visual risk indicators
- **Responsive design** - Works on all devices
- **Charts and graphs** - Visual risk distribution
- **Compliance badges** - ISO 27001, PCI-DSS, OWASP markers

### AI-Enhanced Badges
All AI-generated sections are clearly marked with ü§ñ badges

### Severity Levels
- üî¥ **CRITICAL** - Immediate action required (0-24 hours)
- üü† **HIGH** - Urgent attention (1-7 days)
- üü° **MEDIUM** - Scheduled remediation (1-4 weeks)
- üü¢ **LOW** - Long-term improvements (1-3 months)
- üîµ **INFO** - Informational only

## üîí Compliance Frameworks Covered

### ISO/IEC 27001
- Information Security Management controls
- Risk treatment requirements
- Access control mappings

### PCI-DSS
- Payment card data security
- Vulnerability management requirements
- Secure development lifecycle

### OWASP Top 10
- Web application security risks
- API security concerns
- Modern threat landscape

### CWE/SANS Top 25
- Common Weakness Enumeration
- Dangerous software errors
- Industry best practices

### NIST Cybersecurity Framework
- Identify, Protect, Detect, Respond, Recover
- Risk management framework
- Security controls catalog

## üîß Customization

### Adjusting AI Model Parameters

Edit `llm_integration.py`:

```python
# Increase response length
response = llm.generate(prompt, max_length=3000)

# Adjust creativity (0.0 = deterministic, 1.0 = creative)
response = llm.generate(prompt, temperature=0.9)
```

### Custom Report Templates

Edit `html_report_generator.py`:

```python
# Modify CSS styles
def _get_css_styles(self):
    return """
    <style>
        /* Add your custom styles here */
    </style>
    """

# Add custom sections
def generate_custom_section(self, data):
    return f'<div class="section">{data}</div>'
```

### Adding New Security Tools

Edit `reports/process_vulnerabilities.py`:

```python
def normalize_new_tool(self, report_path: Path) -> List[Dict[str, Any]]:
    """Normalize new security tool report."""
    # Parse your tool's JSON format
    # Return list of normalized vulnerabilities
    pass

# Register in process_all_reports()
reports = {
    'your-tool-report.json': self.normalize_new_tool,
}
```

## üìä Jenkins Integration

The pipeline is fully integrated with Jenkins:

### Environment Variables
```groovy
environment {
    HF_TOKEN_CREDENTIALS_ID = 'huggingface-token'
    REPORTS_DIR = 'reports'
    PROCESSED_DIR = 'processed'
    AI_POLICIES_DIR = 'ai-policies'
}
```

### Automated Stages
1. **Prepare Directories** - Creates report folders
2. **Gitleaks** - Secrets scanning
3. **Semgrep** - SAST analysis
4. **Dependency-Check** - SCA scanning
5. **Build Docker Image** - Application build
6. **Run Tests** - Unit/integration tests
7. **Trivy** - Container scanning
8. **Push to Docker Hub** - Image registry
9. **Deploy** - Application deployment
10. **OWASP ZAP** - DAST scanning
11. **Normalize Reports** - Vulnerability consolidation
12. **AI Policy Generation** - LLM analysis
13. **Archive Reports** - Artifact storage
14. **Grafana Notification** - Monitoring integration

### Accessing Reports

Jenkins automatically archives all reports as build artifacts:
- Navigate to build > Artifacts
- Download HTML reports for viewing
- Download JSON for programmatic access

## üêõ Troubleshooting

### HuggingFace API Issues

**Problem:** Model loading timeout
```
Error: HTTP 503 - Model is loading
```

**Solution:** Retry with exponential backoff (implemented automatically)
```python
# Increase max_retries in llm_integration.py
result = self.provider.query(model_id, payload, max_retries=5)
```

**Problem:** Rate limiting
```
Error: HTTP 429 - Too many requests
```

**Solution:**
- Use HuggingFace Pro account for higher rate limits
- Add delays between requests
- Consider self-hosting models

### Report Generation Issues

**Problem:** Empty or missing reports
```
Error: Report not found: gitleaks-report.json
```

**Solution:**
- Ensure security scan completed successfully
- Check Docker volume mounts
- Verify file permissions

**Problem:** AI generation fails
```
AI policy generation completed with warnings
```

**Solution:**
- Verify HF_TOKEN is valid
- Check internet connectivity
- Review HuggingFace API status
- Fallback to placeholder reports

### HTML Report Rendering

**Problem:** Broken styles in browser
```
Report looks unstyled
```

**Solution:**
- Open HTML file directly (not via file:// protocol from network drive)
- Use modern browser (Chrome, Firefox, Edge)
- Check browser console for errors

## üìà Performance Optimization

### For Large Codebases

```bash
# Limit Semgrep scope
semgrep scan --config=p/python --exclude=tests/ --exclude=venv/

# Limit Trivy to specific severities
trivy image --severity CRITICAL,HIGH your-image:tag

# Process top vulnerabilities only
head -n 100 normalized_vulnerabilities.json
```

### For Faster AI Generation

```python
# Use lighter models
llm = SecurityAnalysisLLM(token, preferred_model="llama")

# Reduce max_length
response = llm.generate(prompt, max_length=1000)

# Skip optional sections
# Comment out in real_llm_integration.py
```

## ü§ù Contributing

To extend this pipeline:

1. **Add new security tool:**
   - Create normalizer in `process_vulnerabilities.py`
   - Add stage in `jenkinsfile`
   - Update documentation

2. **Enhance AI prompts:**
   - Edit prompts in `llm_integration.py`
   - Test with sample data
   - Validate output quality

3. **Improve HTML reports:**
   - Modify templates in `html_report_generator.py`
   - Add new visualizations
   - Enhance styling

## üìö Additional Resources

- [HuggingFace Inference API Docs](https://huggingface.co/docs/api-inference)
- [DeepSeek R1 Model Card](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)
- [Llama 3.2 Documentation](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [ISO 27001 Standard](https://www.iso.org/isoiec-27001-information-security.html)
- [PCI-DSS Requirements](https://www.pcisecuritystandards.org/)

## üìÑ License

This project is part of the Intelligent Stock Market Monitoring Platform.
¬© 2025 | All rights reserved

## üôè Acknowledgments

- **HuggingFace** - For providing free inference API
- **DeepSeek AI** - For the DeepSeek R1 model
- **Meta** - For Llama models
- **OWASP** - For security tools and standards
- **Open Source Community** - For all security scanning tools

---

**For support or questions, please open an issue on GitHub.**
