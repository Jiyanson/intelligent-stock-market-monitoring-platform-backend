#!/usr/bin/env python3
"""
Vulnerability Pipeline Validation Script

This script validates the complete vulnerability processing pipeline:
1. Checks if normalized vulnerability data exists and is properly formatted
2. Validates vulnerability counts match between different fields
3. Analyzes the distribution of vulnerabilities
4. Tests the improved LLM integration
5. Generates a detailed diagnostic report

Usage:
    python3 validate_vulnerability_pipeline.py
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any
from collections import Counter


class VulnerabilityPipelineValidator:
    """Validates the entire vulnerability processing pipeline."""

    def __init__(self):
        self.reports_dir = Path("reports")
        self.processed_dir = Path("processed")
        self.normalized_file = self.processed_dir / "normalized_vulnerabilities.json"

        self.results = {
            "checks_passed": 0,
            "checks_failed": 0,
            "warnings": [],
            "errors": [],
            "info": []
        }

    def run_all_checks(self):
        """Run all validation checks."""
        print("="*80)
        print("VULNERABILITY PIPELINE VALIDATION")
        print("="*80)

        print("\n[1/6] Checking directory structure...")
        self.check_directory_structure()

        print("\n[2/6] Checking raw security scan reports...")
        self.check_raw_reports()

        print("\n[3/6] Validating normalized vulnerability data...")
        self.validate_normalized_data()

        print("\n[4/6] Analyzing vulnerability distribution...")
        self.analyze_vulnerability_distribution()

        print("\n[5/6] Checking data integrity...")
        self.check_data_integrity()

        print("\n[6/6] Testing improved LLM integration...")
        self.test_llm_integration()

        print("\n" + "="*80)
        self.print_summary()

    def check_directory_structure(self):
        """Check if required directories exist."""
        required_dirs = [
            self.reports_dir,
            self.processed_dir,
            Path("ai-reports"),
            Path("ai-policies")
        ]

        for dir_path in required_dirs:
            if dir_path.exists():
                self._pass(f"Directory exists: {dir_path}")
            else:
                self._warn(f"Directory missing: {dir_path}")

    def check_raw_reports(self):
        """Check if raw security scan reports exist."""
        expected_reports = [
            "gitleaks-report.json",
            "semgrep-report.json",
            "dependency-check-report.json",
            "trivy-report.json",
            "zap-report.json"
        ]

        found_reports = []
        missing_reports = []

        for report in expected_reports:
            report_path = self.reports_dir / report
            if report_path.exists():
                # Check file size
                size = report_path.stat().st_size
                found_reports.append(report)
                self._info(f"Found {report} ({size:,} bytes)")

                # Quick scan of Trivy report for vulnerability count
                if report == "trivy-report.json":
                    try:
                        with open(report_path, 'r') as f:
                            trivy_data = json.load(f)
                        vuln_count = sum(
                            len(result.get('Vulnerabilities', []))
                            for result in trivy_data.get('Results', [])
                        )
                        self._info(f"  Trivy report contains {vuln_count} vulnerabilities")
                    except Exception as e:
                        self._warn(f"  Could not parse Trivy report: {e}")
            else:
                missing_reports.append(report)
                self._warn(f"Missing report: {report}")

        if found_reports:
            self._pass(f"Found {len(found_reports)}/{len(expected_reports)} security scan reports")
        else:
            self._fail(f"No security scan reports found in {self.reports_dir}")

    def validate_normalized_data(self):
        """Validate the normalized vulnerability data."""
        if not self.normalized_file.exists():
            self._fail(f"Normalized data file not found: {self.normalized_file}")
            return None

        try:
            with open(self.normalized_file, 'r') as f:
                data = json.load(f)

            # Check required keys
            required_keys = ['metadata', 'risk_metrics', 'tool_summary', 'vulnerabilities']
            missing_keys = [key for key in required_keys if key not in data]

            if missing_keys:
                self._fail(f"Missing required keys in normalized data: {missing_keys}")
                return None

            self._pass("Normalized data has all required keys")

            # Check metadata
            metadata = data.get('metadata', {})
            self._info(f"Scan date: {metadata.get('scan_date', 'Unknown')}")
            self._info(f"Processed tools: {metadata.get('processed_tools', 0)}/{metadata.get('total_tools', 0)}")

            return data

        except json.JSONDecodeError as e:
            self._fail(f"Invalid JSON in normalized data: {e}")
            return None
        except Exception as e:
            self._fail(f"Error reading normalized data: {e}")
            return None

    def analyze_vulnerability_distribution(self):
        """Analyze the distribution of vulnerabilities."""
        if not self.normalized_file.exists():
            self._warn("Cannot analyze distribution - normalized data not found")
            return

        try:
            with open(self.normalized_file, 'r') as f:
                data = json.load(f)

            vulnerabilities = data.get('vulnerabilities', [])
            risk_metrics = data.get('risk_metrics', {})
            tool_summary = data.get('tool_summary', {})

            print(f"\n  VULNERABILITY STATISTICS:")
            print(f"  {'─'*60}")

            # Risk metrics
            total = risk_metrics.get('total', 0)
            critical = risk_metrics.get('critical', 0)
            high = risk_metrics.get('high', 0)
            medium = risk_metrics.get('medium', 0)
            low = risk_metrics.get('low', 0)

            print(f"  Total Vulnerabilities: {total}")
            print(f"    • CRITICAL: {critical}")
            print(f"    • HIGH: {high}")
            print(f"    • MEDIUM: {medium}")
            print(f"    • LOW: {low}")
            print(f"  Risk Level: {risk_metrics.get('risk_level', 'UNKNOWN')}")
            print(f"  Risk Score: {risk_metrics.get('risk_score', 0)}")

            # Tool summary
            print(f"\n  FINDINGS BY TOOL:")
            print(f"  {'─'*60}")
            for tool, info in tool_summary.items():
                count = info.get('count', 0)
                status = info.get('status', 'ok')
                if status == 'not_found':
                    print(f"    • {tool}: Not executed")
                else:
                    print(f"    • {tool}: {count} findings")

            # Vulnerability array analysis
            vuln_array_len = len(vulnerabilities)
            print(f"\n  DATA INTEGRITY:")
            print(f"  {'─'*60}")
            print(f"  Vulnerabilities in array: {vuln_array_len}")
            print(f"  Total in risk_metrics: {total}")

            if vuln_array_len == total:
                self._pass("Vulnerability counts match between array and risk_metrics")
            else:
                self._fail(
                    f"COUNT MISMATCH: Array has {vuln_array_len} items "
                    f"but risk_metrics reports {total}"
                )

            # Analyze by category
            if vulnerabilities:
                categories = Counter(v.get('category', 'Unknown') for v in vulnerabilities)
                print(f"\n  BREAKDOWN BY CATEGORY:")
                print(f"  {'─'*60}")
                for category, count in categories.most_common():
                    print(f"    • {category}: {count}")

                # Analyze by package (for container vulnerabilities)
                packages = Counter(
                    v.get('package', v.get('file', 'Unknown'))
                    for v in vulnerabilities
                    if v.get('category') == 'Container Security'
                )
                if packages:
                    print(f"\n  TOP 10 VULNERABLE PACKAGES:")
                    print(f"  {'─'*60}")
                    for pkg, count in packages.most_common(10):
                        # Count critical/high for this package
                        pkg_vulns = [
                            v for v in vulnerabilities
                            if v.get('package', v.get('file')) == pkg
                        ]
                        critical_count = sum(1 for v in pkg_vulns if v.get('severity', '').upper() == 'CRITICAL')
                        high_count = sum(1 for v in pkg_vulns if v.get('severity', '').upper() == 'HIGH')

                        print(f"    • {pkg}: {count} total ({critical_count} CRITICAL, {high_count} HIGH)")

        except Exception as e:
            self._fail(f"Error analyzing vulnerability distribution: {e}")

    def check_data_integrity(self):
        """Check for data integrity issues."""
        try:
            with open(self.normalized_file, 'r') as f:
                data = json.load(f)

            vulnerabilities = data.get('vulnerabilities', [])

            # Check for required fields in vulnerabilities
            required_fields = ['id', 'tool', 'severity', 'title']
            issues = []

            for i, vuln in enumerate(vulnerabilities[:10]):  # Check first 10
                missing = [field for field in required_fields if field not in vuln]
                if missing:
                    issues.append(f"Vulnerability {i}: missing fields {missing}")

            if issues:
                for issue in issues:
                    self._warn(issue)
            else:
                self._pass("All vulnerabilities have required fields")

            # Check severity values
            valid_severities = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO', 'INFORMATIONAL', 'NEGLIGIBLE']
            invalid_severities = [
                v.get('severity', 'UNKNOWN')
                for v in vulnerabilities
                if v.get('severity', '').upper() not in valid_severities
            ]

            if invalid_severities:
                self._warn(f"Found invalid severity values: {set(invalid_severities)}")
            else:
                self._pass("All severity values are valid")

        except Exception as e:
            self._fail(f"Error checking data integrity: {e}")

    def test_llm_integration(self):
        """Test the improved LLM integration."""
        try:
            # Import the improved module
            from improved_llm_integration import (
                SecurityAnalysisLLM,
                VulnerabilityAnalyzer,
                validate_vulnerability_data
            )

            # Validate data using the improved validation
            validation = validate_vulnerability_data(str(self.normalized_file))

            if validation["errors"]:
                self._fail("LLM Integration validation failed:")
                for error in validation["errors"]:
                    print(f"      • {error}")
                return

            if validation["warnings"]:
                for warning in validation["warnings"]:
                    self._warn(f"LLM Integration: {warning}")

            if validation["valid"]:
                self._pass("Improved LLM integration validation passed")

                # Test the analyzer
                analyzer = VulnerabilityAnalyzer()
                analysis = analyzer.analyze_vulnerabilities(
                    validation["data"]["vulnerabilities"]
                )

                print(f"\n  LLM INTEGRATION ANALYSIS:")
                print(f"  {'─'*60}")
                print(f"  Total vulnerabilities analyzed: {analysis['total_count']}")
                print(f"  Critical/High vulnerabilities: {len(analysis['critical_high_details'])}")
                print(f"  Packages analyzed: {len(analysis['by_package'])}")
                print(f"  Categories found: {len(analysis['by_category'])}")

                self._pass("Vulnerability analyzer working correctly")

                # Check if HF_TOKEN is set
                if os.environ.get('HF_TOKEN'):
                    self._info("HF_TOKEN is set - LLM can generate reports")
                else:
                    self._warn("HF_TOKEN not set - LLM report generation will fail")

        except ImportError as e:
            self._fail(f"Could not import improved_llm_integration: {e}")
        except Exception as e:
            self._fail(f"Error testing LLM integration: {e}")

    def _pass(self, message: str):
        """Record a passed check."""
        print(f"  ✅ {message}")
        self.results["checks_passed"] += 1

    def _fail(self, message: str):
        """Record a failed check."""
        print(f"  ❌ {message}")
        self.results["checks_failed"] += 1
        self.results["errors"].append(message)

    def _warn(self, message: str):
        """Record a warning."""
        print(f"  ⚠️  {message}")
        self.results["warnings"].append(message)

    def _info(self, message: str):
        """Record an info message."""
        print(f"  ℹ️  {message}")
        self.results["info"].append(message)

    def print_summary(self):
        """Print validation summary."""
        print("VALIDATION SUMMARY")
        print("="*80)

        total_checks = self.results["checks_passed"] + self.results["checks_failed"]
        success_rate = (self.results["checks_passed"] / total_checks * 100) if total_checks > 0 else 0

        print(f"\nChecks Passed: {self.results['checks_passed']}/{total_checks} ({success_rate:.1f}%)")
        print(f"Checks Failed: {self.results['checks_failed']}")
        print(f"Warnings: {len(self.results['warnings'])}")

        if self.results["checks_failed"] == 0:
            print("\n✅ All critical checks passed!")
            print("\nNext steps:")
            print("  1. Run: python3 improved_llm_integration.py")
            print("     to validate the improved integration")
            print("  2. Run: python3 real_llm_integration.py")
            print("     to generate AI-powered reports with accurate vulnerability counts")
        else:
            print("\n❌ Some checks failed. Please review errors above.")

            if not Path("processed/normalized_vulnerabilities.json").exists():
                print("\nQuick fix:")
                print("  1. Ensure security scans have run")
                print("  2. Run: cd reports && python3 process_vulnerabilities.py")
                print("  3. Run this validation script again")

        print("\n" + "="*80)


def main():
    """Main entry point."""
    validator = VulnerabilityPipelineValidator()
    validator.run_all_checks()


if __name__ == "__main__":
    main()
