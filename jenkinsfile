pipeline {
    agent any

    environment {
        // Docker Registry
        DOCKER_REGISTRY = 'docker.io'
        DOCKER_USERNAME = 'michoc'
        IMAGE_NAME = "${DOCKER_USERNAME}/stock-market-platform"
        AI_PROCESSOR_IMAGE = "${DOCKER_USERNAME}/ai-security-processor"
        DOCKER_CREDENTIALS_ID = '2709ba15-3bf5-42b4-a41e-e2ae435f4951'
        IMAGE_TAG = "${env.BUILD_NUMBER}"

        // SonarQube
        SONAR_PROJECT_KEY = 'stock-market-platform'
        SONAR_HOST_URL = 'http://localhost:9000'
        SONAR_LOGIN_ID = 'sonarqube-token'

        // HuggingFace for AI
        HF_TOKEN_CREDENTIALS_ID = 'huggingface-token'
        HF_MODEL = 'deepseek-ai/DeepSeek-R1'

        // Grafana
        GRAFANA_URL = 'https://ayoubcpge9.grafana.net'
        GRAFANA_API_KEY_CREDENTIALS_ID = '0acea52d-149d-4dce-affc-6e88b440471e'
        GRAFANA_DASHBOARD_ID = '1'

        // Git
        GIT_REPO_URL = 'https://github.com/Jiyanson/intelligent-stock-market-monitoring-platform-backend.git'
        GIT_BRANCH = 'main'
    }

    stages {
        // ====================================
        // PHASE 1: INITIALIZATION
        // ====================================
        stage('Checkout') {
            steps {
                echo 'üì¶ Source code already checked out by Jenkins SCM'
                sh 'pwd && ls -la'
            }
        }

        stage('Initialize Directories') {
            steps {
                script {
                    echo 'üìÅ Creating report directories...'
                    sh '''
                        mkdir -p reports processed ai-reports ai-policies
                        chmod -R 777 reports processed ai-reports ai-policies 2>/dev/null || true
                        echo "‚úÖ Directories initialized with full write permissions"
                        ls -la | grep -E "reports|processed|ai-"
                    '''
                }
            }
        }

        // ====================================
        // PHASE 2: PRE-COMMIT SECURITY
        // ====================================
        stage('Pre-commit Security') {
            parallel {
                stage('Secrets Scanning - Gitleaks') {
                    steps {
                        script {
                            echo 'üïµÔ∏è Running Gitleaks secrets scan...'
                            sh '''
                                docker run --rm -v ${PWD}:/workspace \\
                                    zricethezav/gitleaks:latest \\
                                    detect --source /workspace \\
                                    --report-path /workspace/reports/gitleaks-report.json \\
                                    --report-format json \\
                                    --no-git || echo "Gitleaks scan completed"

                                if [ -f reports/gitleaks-report.json ]; then
                                    LEAK_COUNT=$(jq length reports/gitleaks-report.json 2>/dev/null || echo "0")
                                    echo "‚úÖ Gitleaks: Detected $LEAK_COUNT potential secrets"
                                else
                                    echo "[]" > reports/gitleaks-report.json
                                fi
                            '''
                        }
                    }
                }

                stage('SAST - Semgrep') {
                    steps {
                        script {
                            echo 'üîç Running Semgrep SAST scan...'
                            sh '''
                                docker run --rm -v ${PWD}:/src \\
                                    returntocorp/semgrep \\
                                    semgrep scan --config=p/python \\
                                    --json --output=/src/reports/semgrep-report.json \\
                                    /src || echo "Semgrep scan completed"

                                if [ ! -f reports/semgrep-report.json ]; then
                                    echo '{"results":[]}' > reports/semgrep-report.json
                                fi
                                echo "‚úÖ Semgrep scan completed"
                            '''
                        }
                    }
                }
            }
        }

        // ====================================
        // PHASE 3: BUILD STAGE
        // ====================================
        stage('Build Main Application Image') {
            steps {
                script {
                    echo "üê≥ Building main Docker image: ${IMAGE_NAME}:${IMAGE_TAG}"
                    sh """
                        docker build -t ${IMAGE_NAME}:${IMAGE_TAG} .
                        docker tag ${IMAGE_NAME}:${IMAGE_TAG} ${IMAGE_NAME}:latest
                        echo "‚úÖ Main application image built successfully"
                    """
                }
            }
        }

        stage('Prepare AI Processor Image') {
            steps {
                script {
                    echo "ü§ñ Preparing AI Processor image..."
                    sh """
                        # Try to pull pre-built image from registry first (fast path)
                        echo "üì• Attempting to pull AI Processor image from registry..."
                        if docker pull ${AI_PROCESSOR_IMAGE}:latest 2>/dev/null; then
                            echo "‚úÖ Using cached AI Processor image from registry (~10 seconds)"
                            docker tag ${AI_PROCESSOR_IMAGE}:latest ${AI_PROCESSOR_IMAGE}:${IMAGE_TAG}
                        else
                            echo "‚ö†Ô∏è  No cached image found in registry"
                            echo "üî® Building AI Processor image (first run only, takes ~5-10 minutes)..."
                            echo "üí° This image will be cached for future pipeline runs"

                            # Build the image with BuildKit for better caching
                            DOCKER_BUILDKIT=1 docker build -f Dockerfile.ai-processor \\
                                -t ${AI_PROCESSOR_IMAGE}:latest \\
                                -t ${AI_PROCESSOR_IMAGE}:${IMAGE_TAG} .

                            echo "‚úÖ AI Processor image built successfully"
                            echo "üì§ Image will be pushed to registry in Phase 8 for future runs"
                        fi
                    """
                }
            }
        }

        // ====================================
        // PHASE 4: SECURITY SCANNING (PARALLEL)
        // ====================================
        stage('Initialize Trivy Database') {
            steps {
                script {
                    echo 'üì• Downloading Trivy vulnerability database (one-time setup)...'
                    sh '''
                        # Create Trivy cache directory
                        mkdir -p ${HOME}/.cache/trivy

                        # Download/update Trivy DB with extended timeout
                        echo "‚è≥ Downloading vulnerability database (this may take a few minutes on first run)..."
                        docker run --rm \\
                            -v ${HOME}/.cache/trivy:/root/.cache/trivy \\
                            aquasec/trivy:latest \\
                            image --download-db-only --timeout 15m || {
                                echo "‚ö†Ô∏è  DB download timeout - will use offline mode for scans"
                                touch ${HOME}/.cache/trivy/db-failed
                            }

                        if [ -f ${HOME}/.cache/trivy/db-failed ]; then
                            echo "‚ö†Ô∏è  Trivy DB download failed - scans will run in offline mode with cached data"
                        else
                            echo "‚úÖ Trivy vulnerability database ready"
                        fi
                    '''
                }
            }
        }

        stage('Security Scanning') {
            parallel {
                stage('SCA - OWASP Dependency Check') {
                    steps {
                        script {
                            echo 'üì¶ Running OWASP Dependency-Check (SCA)...'
                            sh '''
                                # Create reports directory
                                mkdir -p reports

                                # Check if Trivy DB is available
                                if [ -f ${HOME}/.cache/trivy/db-failed ]; then
                                    DB_UPDATE_FLAG="--skip-db-update"
                                    echo "‚ö†Ô∏è  Using offline mode (DB unavailable)"
                                else
                                    DB_UPDATE_FLAG="--skip-db-update"
                                    echo "‚úÖ Using cached vulnerability database"
                                fi

                                # Using Trivy for comprehensive dependency scanning
                                echo "üîç Scanning Python dependencies with Trivy..."
                                docker run --rm \\
                                    -v ${HOME}/.cache/trivy:/root/.cache/trivy \\
                                    -v ${PWD}:/workspace \\
                                    -v ${PWD}/reports:/reports \\
                                    aquasec/trivy:latest \\
                                    fs ${DB_UPDATE_FLAG} \\
                                    --format json \\
                                    --output /reports/dependency-check-report.json \\
                                    --scanners vuln \\
                                    --severity CRITICAL,HIGH,MEDIUM,LOW \\
                                    --list-all-pkgs \\
                                    --timeout 10m \\
                                    /workspace || echo "Dependency check completed"

                                # Generate HTML report
                                docker run --rm \\
                                    -v ${HOME}/.cache/trivy:/root/.cache/trivy \\
                                    -v ${PWD}:/workspace \\
                                    -v ${PWD}/reports:/reports \\
                                    aquasec/trivy:latest \\
                                    fs ${DB_UPDATE_FLAG} \\
                                    --format template \\
                                    --template '@contrib/html.tpl' \\
                                    --output /reports/dependency-check-report.html \\
                                    --scanners vuln \\
                                    --severity CRITICAL,HIGH,MEDIUM,LOW \\
                                    --timeout 10m \\
                                    /workspace || true

                                # Ensure report exists (create empty if scanning failed)
                                if [ ! -f reports/dependency-check-report.json ]; then
                                    echo '{"Results":[]}' > reports/dependency-check-report.json
                                    echo "‚ö†Ô∏è No dependency vulnerabilities found or scan failed - created empty report"
                                else
                                    # Count vulnerabilities
                                    VULN_COUNT=$(python3 -c "import json; data=json.load(open('reports/dependency-check-report.json')); print(sum(len(r.get('Vulnerabilities', [])) for r in data.get('Results', [])))" 2>/dev/null || echo "0")
                                    echo "‚úÖ Dependency scan found ${VULN_COUNT} vulnerabilities"
                                fi

                                echo "‚úÖ OWASP Dependency-Check completed"
                            '''
                        }
                    }
                }

                stage('Container Scan - Trivy') {
                    steps {
                        script {
                            echo 'üîí Running Trivy container image scan...'
                            sh """
                                # Use cached DB
                                docker run --rm \\
                                    -v ${HOME}/.cache/trivy:/root/.cache/trivy \\
                                    -v /var/run/docker.sock:/var/run/docker.sock \\
                                    -v \${PWD}/reports:/reports \\
                                    aquasec/trivy:latest \\
                                    image --skip-db-update \\
                                    --format json \\
                                    --output /reports/trivy-image-scan.json \\
                                    --timeout 10m \\
                                    ${IMAGE_NAME}:${IMAGE_TAG} || echo "Trivy scan completed"

                                # Generate HTML report
                                docker run --rm \\
                                    -v ${HOME}/.cache/trivy:/root/.cache/trivy \\
                                    -v /var/run/docker.sock:/var/run/docker.sock \\
                                    -v \${PWD}/reports:/reports \\
                                    aquasec/trivy:latest \\
                                    image --skip-db-update \\
                                    --format template \\
                                    --template '@contrib/html.tpl' \\
                                    --output /reports/trivy-report.html \\
                                    --timeout 10m \\
                                    ${IMAGE_NAME}:${IMAGE_TAG} || true

                                # Fix permissions on report files
                                chmod 666 reports/*.json reports/*.html 2>/dev/null || true

                                # Count vulnerabilities found
                                if [ -f reports/trivy-image-scan.json ]; then
                                    VULN_COUNT=\$(python3 -c "import json; data=json.load(open('reports/trivy-image-scan.json')); print(sum(len(r.get('Vulnerabilities', [])) for r in data.get('Results', [])))" 2>/dev/null || echo "0")
                                    echo "‚úÖ Container scan found \${VULN_COUNT} vulnerabilities"
                                else
                                    echo '{"Results":[]}' > reports/trivy-image-scan.json
                                fi
                            """
                        }
                    }
                }

                stage('SAST - SonarQube') {
                    steps {
                        script {
                            echo 'üìä Running SonarQube code quality analysis...'

                            // Check if SonarQube is actually configured and reachable
                            def sonarConfigured = false
                            try {
                                withCredentials([string(credentialsId: SONAR_LOGIN_ID, variable: 'SONAR_TOKEN')]) {
                                    // Check if token exists and is not empty
                                    if (env.SONAR_TOKEN && env.SONAR_TOKEN.trim()) {
                                        sonarConfigured = true
                                    }
                                }
                            } catch (Exception e) {
                                sonarConfigured = false
                            }

                            if (!sonarConfigured) {
                                echo "‚ö†Ô∏è SonarQube not configured - skipping analysis"
                                echo "üí° To enable SonarQube:"
                                echo "   1. Install and run SonarQube server"
                                echo "   2. Add credentials with ID: ${SONAR_LOGIN_ID}"
                                echo "   3. Update SONAR_HOST_URL in Jenkinsfile"
                                echo ""
                                echo "‚è© Continuing pipeline without SonarQube..."
                            } else {
                                // SonarQube is configured, check if server is reachable
                                def serverReachable = sh(
                                    script: """
                                        # Try to ping SonarQube server (use host network for Docker)
                                        # Check if we're using localhost and convert to host.docker.internal for Docker
                                        SONAR_URL="${SONAR_HOST_URL}"
                                        if [[ "\${SONAR_URL}" == *"localhost"* ]]; then
                                            echo "‚ö†Ô∏è SonarQube URL uses 'localhost' - may not be reachable from Docker"
                                            # Try using host.docker.internal for Docker Desktop
                                            curl -s -o /dev/null -w "%{http_code}" "http://host.docker.internal:9000/api/system/status" 2>/dev/null | grep -q "200" && echo "reachable" || echo "unreachable"
                                        else
                                            # Check if external SonarQube server is reachable
                                            curl -s -o /dev/null -w "%{http_code}" "\${SONAR_URL}/api/system/status" 2>/dev/null | grep -q "200" && echo "reachable" || echo "unreachable"
                                        fi
                                    """,
                                    returnStdout: true
                                ).trim()

                                if (serverReachable == "reachable") {
                                    echo "‚úÖ SonarQube server is reachable, starting scan..."
                                    withCredentials([string(credentialsId: SONAR_LOGIN_ID, variable: 'SONAR_TOKEN')]) {
                                        sh '''
                                            # Adjust SonarQube URL for Docker containers
                                            SONAR_URL="${SONAR_HOST_URL}"
                                            if [[ "${SONAR_URL}" == *"localhost"* ]]; then
                                                SONAR_URL="http://host.docker.internal:9000"
                                                echo "üîß Adjusted SonarQube URL for Docker: ${SONAR_URL}"
                                            fi

                                            if ! command -v sonar-scanner &> /dev/null; then
                                                echo "Running SonarScanner via Docker with host network..."
                                                docker run --rm \\
                                                    --network host \\
                                                    -e SONAR_HOST_URL="${SONAR_URL}" \\
                                                    -e SONAR_TOKEN="${SONAR_TOKEN}" \\
                                                    -v "${PWD}:/usr/src" \\
                                                    sonarsource/sonar-scanner-cli:latest \\
                                                    -Dsonar.projectKey=${SONAR_PROJECT_KEY} \\
                                                    -Dsonar.sources=app/ \\
                                                    -Dsonar.language=python \\
                                                    -Dsonar.python.coverage.reportPaths=coverage.xml || echo "‚ö†Ô∏è SonarQube scan completed with warnings"
                                            else
                                                sonar-scanner \\
                                                    -Dsonar.projectKey=${SONAR_PROJECT_KEY} \\
                                                    -Dsonar.sources=app/ \\
                                                    -Dsonar.language=python \\
                                                    -Dsonar.host.url=${SONAR_URL} \\
                                                    -Dsonar.token=${SONAR_TOKEN} || echo "‚ö†Ô∏è SonarQube scan completed with warnings"
                                            fi

                                            echo "‚úÖ SonarQube analysis completed"
                                        '''
                                    }
                                } else {
                                    echo "‚ö†Ô∏è SonarQube server not reachable at: ${SONAR_HOST_URL}"
                                    echo "üí° Possible solutions:"
                                    echo "   1. Start SonarQube server: docker run -d -p 9000:9000 sonarqube:latest"
                                    echo "   2. Update SONAR_HOST_URL to point to your SonarQube instance"
                                    echo "   3. Ensure SonarQube is running and accessible from Jenkins"
                                    echo ""
                                    echo "‚è© Skipping SonarQube analysis and continuing pipeline..."
                                }
                            }
                        }
                    }
                }
            }
        }

        // ====================================
        // PHASE 5: DAST
        // ====================================
        stage('Deploy for DAST') {
            steps {
                script {
                    echo 'üöÄ Deploying application for DAST testing...'
                    sh """
                        # Clean up existing deployment
                        echo "üßπ Cleaning up existing containers..."
                        docker compose down --remove-orphans --volumes || true
                        docker rm -f postgres_db redis_cache pgadmin 2>/dev/null || true
                        docker ps -a --filter "name=devsecops2" --format "{{.Names}}" | xargs -r docker rm -f 2>/dev/null || true
                        docker network prune -f || true

                        # Wait for ports to be released
                        echo "‚è≥ Waiting for ports to be released..."
                        sleep 3

                        # Check and free critical ports
                        for port in 8000 5432 6379; do
                            if lsof -i :\${port} >/dev/null 2>&1; then
                                echo "‚ö†Ô∏è  Warning: Port \${port} is still in use"
                                lsof -ti :\${port} | xargs -r kill -9 2>/dev/null || true
                                sleep 2
                            else
                                echo "‚úÖ Port \${port} is free"
                            fi
                        done

                        # Pull and start services
                        echo "üì• Pulling latest image..."
                        docker pull ${IMAGE_NAME}:latest

                        echo "üöÄ Starting services..."
                        docker compose up -d

                        # Wait for services to be healthy
                        echo "‚è≥ Waiting for services to start..."
                        sleep 15

                        # Verify services are running
                        echo "üìä Running containers:"
                        docker compose ps

                        # Test connectivity
                        echo "üîç Testing service connectivity..."
                        for i in {1..30}; do
                            if curl -f -s http://localhost:8000/health >/dev/null 2>&1 || curl -f -s http://localhost:8000/docs >/dev/null 2>&1; then
                                echo "‚úÖ Web service is responding"
                                break
                            else
                                echo "‚è≥ Waiting for service to be ready (\$i/30)..."
                                sleep 2
                            fi
                        done
                    """
                }
            }
        }

        stage('DAST - OWASP ZAP') {
            steps {
                script {
                    echo 'üï∑Ô∏è Running OWASP ZAP DAST scan on deployed application...'
                    sh '''
                        TARGET_URL="http://localhost:8000"

                        # Ensure reports directory exists with proper permissions
                        mkdir -p reports
                        chmod 777 reports  # Allow ZAP container to write

                        # Test if app is reachable
                        if curl -f -s ${TARGET_URL}/docs >/dev/null 2>&1 || curl -f -s ${TARGET_URL}/health >/dev/null 2>&1; then
                            echo "‚úÖ Application is reachable, starting ZAP scan..."

                            # Run ZAP with user ID mapping to avoid permission issues
                            docker run --rm \\
                                --network="host" \\
                                --user $(id -u):$(id -g) \\
                                -v ${PWD}/reports:/zap/wrk:rw \\
                                ghcr.io/zaproxy/zaproxy:stable \\
                                zap-baseline.py \\
                                -t ${TARGET_URL} \\
                                -J zap-report.json \\
                                -r zap-report.html \\
                                -I || echo "ZAP scan completed with warnings"

                            # Fix permissions on ZAP reports (in case still needed)
                            chmod 666 reports/zap-report.* 2>/dev/null || true

                            if [ -f reports/zap-report.json ]; then
                                echo "‚úÖ DAST scan completed - report saved"
                                # Count alerts
                                ALERT_COUNT=$(python3 -c "import json; data=json.load(open('reports/zap-report.json', 'r')); print(len(data.get('site', [{}])[0].get('alerts', [])))" 2>/dev/null || echo "0")
                                echo "   Found ${ALERT_COUNT} security alerts"
                            else
                                echo "‚ö†Ô∏è  ZAP scan completed but no report generated"
                                echo '{"alerts":[]}' > reports/zap-report.json
                            fi
                        else
                            echo "‚ö†Ô∏è  Application not reachable at ${TARGET_URL}"
                            echo "‚ö†Ô∏è  Skipping DAST scan - ensure application is deployed and running"
                            echo '{"alerts":[]}' > reports/zap-report.json
                        fi
                    '''
                }
            }
        }

        // ====================================
        // PHASE 6: AI-POWERED SECURITY ANALYSIS
        // ====================================
        stage('Normalize Reports') {
            steps {
                script {
                    echo 'üßæ Normalizing all security scan results...'
                    sh '''
                        echo "üìÅ Reports found:"
                        ls -lh reports/*.json 2>/dev/null || echo "No JSON reports found"

                        cd reports
                        python3 process_vulnerabilities.py || echo "Using available reports"
                        cd ..

                        if [ -f processed/normalized_vulnerabilities.json ]; then
                            VULN_COUNT=$(jq '.risk_metrics.total // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            CRITICAL=$(jq '.risk_metrics.critical // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            HIGH=$(jq '.risk_metrics.high // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            echo "‚úÖ Normalized $VULN_COUNT vulnerabilities (Critical: $CRITICAL, High: $HIGH)"
                        else
                            echo "Creating placeholder normalized data..."
                            echo '{"vulnerabilities":[],"risk_metrics":{"total":0}}' > processed/normalized_vulnerabilities.json
                        fi
                    '''
                }
            }
        }

        stage('AI Security Policy Generation') {
            steps {
                script {
                    echo 'ü§ñ Generating AI-powered security policies with DUAL-MODEL COMPARISON...'
                    echo '   Models: DeepSeek R1 vs LLaMA 3.3 70B'
                    withCredentials([string(credentialsId: HF_TOKEN_CREDENTIALS_ID, variable: 'HF_TOKEN')]) {
                        sh """
                            # Use Python 3 directly with mounted scripts (avoids stale Docker image)
                            echo "üî¨ Running dual-model analysis with latest code..."

                            # Install required Python packages if needed
                            pip3 install --quiet requests 2>/dev/null || true

                            # Run dual-model generator directly
                            python3 dual_model_policy_generator.py || echo "Dual-model policy generation completed with warnings"

                            # Generate model comparison HTML report
                            echo "üìä Generating model comparison report..."
                            python3 generate_model_comparison_report.py || echo "Comparison report generation completed"

                            # Generate standard AI reports
                            echo "üìÑ Generating comprehensive AI reports..."
                            python3 generate_ai_reports.py || echo "Report generation completed with warnings"

                            # Display results summary
                            echo ""
                            echo "======================================================================"
                            echo "AI-POWERED SECURITY ANALYSIS COMPLETE"
                            echo "======================================================================"
                            echo ""
                            echo "üìä Generated Artifacts:"
                            ls -lh ai-policies/*.json 2>/dev/null | awk '{print "   ‚Ä¢ " \$9 " (" \$5 ")"}'
                            ls -lh ai-reports/*.html 2>/dev/null | awk '{print "   ‚Ä¢ " \$9 " (" \$5 ")"}'

                            # Show model comparison results
                            if [ -f ai-policies/model_comparison_report.json ]; then
                                echo ""
                                echo "üèÜ Model Comparison Results:"
                                WINNER=\$(python3 -c "import json; data=json.load(open('ai-policies/model_comparison_report.json')); print(data.get('individual_results', {}).get(data.get('winner', 'unknown'), {}).get('model_name', 'N/A'))" 2>/dev/null || echo "N/A")
                                WINNER_SCORE=\$(python3 -c "import json; data=json.load(open('ai-policies/model_comparison_report.json')); print(f\"{data.get('individual_results', {}).get(data.get('winner', 'unknown'), {}).get('quality_score', 0):.1f}\")" 2>/dev/null || echo "0")
                                echo "   Winner: \${WINNER} (Quality Score: \${WINNER_SCORE}/100)"
                            fi

                            echo ""
                            echo "‚úÖ AI security analysis completed successfully"
                            echo "======================================================================"
                        """
                    }
                }
            }
        }

        // ====================================
        // PHASE 7: QUALITY ASSURANCE
        // ====================================
        stage('Run Tests') {
            steps {
                script {
                    echo 'üß™ Running application tests...'
                    sh """
                        # Ensure test dependencies are available
                        NETWORK_NAME=\$(docker network ls --filter name=devsecops --format "{{.Name}}" | head -n 1)
                        if [ -z "\${NETWORK_NAME}" ]; then
                            NETWORK_NAME=\$(docker network ls --format "{{.Name}}" | grep -E "(default|bridge)" | head -n 1)
                        fi

                        echo "Using network: \${NETWORK_NAME}"

                        docker run --rm \\
                            --network="\${NETWORK_NAME}" \\
                            -e DATABASE_URL="postgresql://fastapi:fastapi@db:5432/fastapi_db" \\
                            -e REDIS_URL="redis://redis:6379/0" \\
                            ${IMAGE_NAME}:${IMAGE_TAG} \\
                            sh -c 'pip install pytest pytest-cov && pytest -v --cov || echo "Tests completed"'

                        echo "‚úÖ Tests completed"
                    """
                }
            }
        }

        // ====================================
        // PHASE 8: DEPLOYMENT & REPORTING
        // ====================================
        // stage('Push to Docker Hub') {
        //     steps {
        //         script {
        //             echo 'üöÄ Pushing images to Docker Hub...'
        //             withCredentials([usernamePassword(
        //                 credentialsId: DOCKER_CREDENTIALS_ID,
        //                 usernameVariable: 'DOCKER_USER',
        //                 passwordVariable: 'DOCKER_PASS'
        //             )]) {
        //                 sh """
        //                     echo "\${DOCKER_PASS}" | docker login -u "\${DOCKER_USER}" --password-stdin

        //                     # Push main application image
        //                     echo "üì§ Pushing main application image..."
        //                     docker push ${IMAGE_NAME}:${IMAGE_TAG}
        //                     docker push ${IMAGE_NAME}:latest

        //                     # Push AI processor image (for caching in future runs)
        //                     echo "üì§ Pushing AI processor image for future caching..."
        //                     docker push ${AI_PROCESSOR_IMAGE}:${IMAGE_TAG}
        //                     docker push ${AI_PROCESSOR_IMAGE}:latest

        //                     docker logout
        //                     echo "‚úÖ All images pushed to registry"
        //                 """
        //             }
        //         }
        //     }
        // }

        stage('Archive Reports') {
            steps {
                script {
                    echo 'üì¶ Archiving all security artifacts...'
                    archiveArtifacts artifacts: 'reports/**/*.*, ai-reports/**/*.*, ai-policies/**/*.*, processed/**/*',
                                     allowEmptyArchive: true,
                                     fingerprint: true
                    echo "‚úÖ Artifacts archived and available for download"
                }
            }
        }

        stage('Grafana Notification') {
            steps {
                script {
                    echo 'üì¢ Sending notification to Grafana...'
                    withCredentials([string(credentialsId: GRAFANA_API_KEY_CREDENTIALS_ID, variable: 'GRAFANA_API_KEY')]) {
                        sh """
                            TIME_MS=\$(date +%s%3N)

                            # Load vulnerability metrics
                            CRITICAL=\$(jq -r '.risk_metrics.critical // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            HIGH=\$(jq -r '.risk_metrics.high // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            TOTAL=\$(jq -r '.risk_metrics.total // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")

                            MESSAGE="üîí Security scan completed for ${IMAGE_NAME}:${IMAGE_TAG} - Total: \${TOTAL}, Critical: \${CRITICAL}, High: \${HIGH}"

                            curl -X POST -H "Authorization: Bearer \${GRAFANA_API_KEY}" \\
                                 -H "Content-Type: application/json" \\
                                 -d "{
                                     \\"dashboardId\\": \${GRAFANA_DASHBOARD_ID},
                                     \\"time\\": \${TIME_MS},
                                     \\"tags\\": [\\"devsecops\\", \\"security-scan\\", \\"build-${IMAGE_TAG}\\", \\"ai-analysis\\"],
                                     \\"text\\": \\"\${MESSAGE}\\"
                                 }" \\
                                 "${GRAFANA_URL}/api/annotations" || echo "Grafana notification sent"
                        """
                    }
                }
            }
        }

        stage('Final Summary') {
            steps {
                script {
                    echo 'üìã Generating comprehensive pipeline summary...'
                    sh '''
                        echo ""
                        echo "üéØ =========================================="
                        echo "   DEVSECOPS PIPELINE COMPLETED"
                        echo "=========================================="
                        echo ""
                        echo "üìä SECURITY SCAN RESULTS:"

                        if [ -f processed/normalized_vulnerabilities.json ]; then
                            TOTAL=$(jq -r '.risk_metrics.total // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            CRITICAL=$(jq -r '.risk_metrics.critical // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            HIGH=$(jq -r '.risk_metrics.high // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            MEDIUM=$(jq -r '.risk_metrics.medium // 0' processed/normalized_vulnerabilities.json 2>/dev/null || echo "0")
                            RISK_LEVEL=$(jq -r '.risk_metrics.risk_level // "UNKNOWN"' processed/normalized_vulnerabilities.json 2>/dev/null || echo "UNKNOWN")

                            echo "  üî¥ Critical: $CRITICAL"
                            echo "  üü† High: $HIGH"
                            echo "  üü° Medium: $MEDIUM"
                            echo "  üìä Total: $TOTAL"
                            echo "  ‚ö†Ô∏è  Risk Level: $RISK_LEVEL"
                        else
                            echo "  ‚ÑπÔ∏è  No vulnerability data available"
                        fi

                        echo ""
                        echo "üîß SECURITY TOOLS EXECUTED:"
                        echo "  ‚úì Gitleaks (Secrets Scanning)"
                        echo "  ‚úì Semgrep (SAST)"
                        echo "  ‚úì OWASP Dependency-Check (SCA)"
                        echo "  ‚úì Trivy (Container Scanning)"
                        echo "  ‚úì SonarQube (Code Quality & SAST)"
                        echo "  ‚úì OWASP ZAP (DAST)"
                        echo "  ‚úì DeepSeek R1 (AI Security Analysis)"

                        echo ""
                        echo "üìÅ REPORTS AVAILABLE:"
                        echo "  ‚Ä¢ Raw scans: ./reports/"
                        echo "  ‚Ä¢ AI analysis: ./ai-reports/"
                        echo "  ‚Ä¢ AI policies: ./ai-policies/"
                        echo "  ‚Ä¢ Normalized data: ./processed/"

                        echo ""
                        echo "ü§ñ AI-GENERATED ARTIFACTS:"
                        ls ai-policies/*.json ai-reports/*.html 2>/dev/null | while read f; do
                            echo "  ‚Ä¢ $(basename $f)"
                        done || echo "  ‚Ä¢ No AI artifacts generated"

                        echo ""
                        echo "‚úÖ Pipeline execution completed successfully"
                        echo "=========================================="
                    '''
                }
            }
        }
    }

    post {
        always {
            script {
                sh '''
                    echo "üßπ Cleaning up..."
                    # Clean old images (keep last 5)
                    docker images ${IMAGE_NAME} --format "{{.Tag}}" | tail -n +6 | while read tag; do
                        docker rmi ${IMAGE_NAME}:${tag} 2>/dev/null || true
                    done
                    docker image prune -f || true
                    echo "‚úÖ Cleanup completed"
                '''
            }
        }
        success {
            script {
                sh '''
                    echo ""
                    echo "üéâ =========================================="
                    echo "   PIPELINE COMPLETED SUCCESSFULLY"
                    echo "=========================================="
                    echo ""
                    echo "All security scans, builds, and deployments completed."
                    echo "Review security reports in Jenkins artifacts."
                    echo ""
                '''
            }
        }
        failure {
            script {
                sh '''
                    echo "‚ùå Pipeline failed! Check logs for details."
                '''
            }
        }
    }
}
